<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>이정원</title>
    <description>이정원의 블로그</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Sun, 16 Oct 2016 05:35:59 +0900</pubDate>
    <lastBuildDate>Sun, 16 Oct 2016 05:35:59 +0900</lastBuildDate>
    <generator>Jekyll v3.3.0</generator>
    
      <item>
        <title>Jekyll + Github 블로그 구축</title>
        <description>&lt;h3 id=&quot;jekyll&quot;&gt;왜 Jekyll인가?&lt;/h3&gt;
&lt;p&gt;잘 정리된 글들이 많이 있다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://blog.kalkin7.com/2015/07/07/maintain-a-blog-for-a-long-time/&quot;&gt;내 글을 오래 남기기 위한 블로그 선택&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://xho95.github.io/blog/github/jekyll/git/2016/01/11/Make-a-blog-with-Jekyll.html&quot;&gt;Jekyll 기반의 GitHub Pages에 블로그 만들기&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://blog.suminb.com/post/goodbye-wordpress-hello-jekyll/&quot;&gt;WordPress 에서 Jekyll로&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://blog.saltfactory.net/note/renewal-blog-from-tistory-to-github-pages-via-jekyll.html&quot;&gt;Tistory에서 Jekyll을 이용하여 GitHub Pages로 블로그 이전&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://ilmol.com/2015/01/%EC%9B%8C%EB%93%9C%ED%94%84%EB%A0%88%EC%8A%A4%EC%97%90%EC%84%9C-Jekyll%EB%A1%9C-%EB%A7%88%EC%9D%B4%EA%B7%B8%EB%A0%88%EC%9D%B4%EC%85%98.html&quot;&gt;난 10년된 워드프레스에서 Jekyll로 마이그레이션&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://halryang.net/From-Wordpress-To-Jekyll&quot;&gt;From Wordpress To Jekyll&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;http://halryang.net/search/?tags=jekyll&quot;&gt;한량넷 Jekyll 글모음&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://blog.nacyot.com/articles/2014-01-15-static-site-generator&quot;&gt;정적 웹사이트 생성기의 역습 - 동적 스크립트를 넘어 다시 정적 컨텐츠로&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://lawfully.kr/smart/jekyll.html&quot;&gt;다 만들고 난 후에 발견한 좋은 글&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;section&quot;&gt;디자인 영감을 받은 사이트&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://spoqa.github.io/index.html&quot;&gt;스포카&lt;/a&gt;의 제목 폰트&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://heelog.github.io/development/&quot;&gt;워니님 블로그&lt;/a&gt;의 timeline css style&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://halryang.net/micro/&quot;&gt;잡담 페이지&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.flaticon.com/search?word=github&quot;&gt;아이콘을 구한 대박 사이트 Flaticon&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;done-list-----&quot;&gt;Done list &amp;amp; 기술적인 도움을 받은 사이트&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://blog.saltfactory.net/jekyll/upgrade-github-pages-dependency-versions.html&quot;&gt;Jekyll 설치&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://github.com/badkeyman/documents/wiki/Jekyll%EB%A1%9C-Github-Pages-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0&quot;&gt;Jekyll로 Github Pages 사용하기&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;로컬 웹서버 가동&lt;/li&gt;
  &lt;li&gt;Guthub page 저장소 생성&lt;/li&gt;
  &lt;li&gt;md 파일 Github에 푸쉬하는 스크립트 ./gitpush&lt;/li&gt;
  &lt;li&gt;chmod +x gitpush&lt;/li&gt;
  &lt;li&gt;웹서버 가동&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/smallmuou/Jekyll-Pithy&quot;&gt;Pithy theme&lt;/a&gt; fork &amp;amp; customizing&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://narie.tistory.com/107&quot;&gt;나눔고딕 웹폰트 적용&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;readmore 구현&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://icoconvert.com/&quot;&gt;파비콘(favicon)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://blog.kalkin7.com/2014/03/04/how-to-align-images-on-writing-with-markdown/&quot;&gt;마크다운으로 이미지 정렬&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;카테고리 #name tag 바로가기&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://halryang.net/embed-youtube-responsively/&quot;&gt;유튜브 임베딩&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://nolboo.kim/blog/2014/01/09/upgrade-jekyll-github-blog/&quot;&gt;태그&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;파머링크 생성&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/Shopify/liquid/wiki/Liquid-for-Designers&quot;&gt;Liquid&lt;/a&gt; 문법&lt;/li&gt;
  &lt;li&gt;pagination (v3.3 에서는 Jekyll paginate &lt;a href=&quot;https://github.com/jekyll/jekyll/issues/4124&quot;&gt;지원 중단&lt;/a&gt;)&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://halryang.net/tag-and-archive/&quot;&gt;태그 시스템/아카이브 페이지/전체글 목록&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://cse.google.com/cse/all&quot;&gt;google 검색창 달기&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://loustler.io/2016/09/26/github_pages_blog_google_analytics/&quot;&gt;google analytics&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://cinos81.bitbucket.org/blog/_site/jekyll/2016/01/23/addRobotTxt.html&quot;&gt;구글 검색에 노출하기&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/appkr/blog/blob/master/_posts/2016-02-13-%EB%B8%94%EB%A1%9C%EA%B7%B8-%ED%94%8C%EB%9E%AB%ED%8F%BC-%EC%9D%B4%EC%A0%84-5-disqus-facebook.md&quot;&gt;댓글&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://halryang.net/Disable-comments/&quot;&gt;댓글 잠금&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;워드프레스에서 Jekyll로 이전&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/dreikanter/wp2md&quot;&gt;wd2md.py&lt;/a&gt;을 Jekyll 스타일에 맞게 수정&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;파일이름: Y%%m%d &amp;gt; %Y-%m-%d
f.write(‘—‘)&lt;br /&gt;
f.write(‘layout: post \n —‘)&lt;br /&gt;
‘post_name’, 삭제&lt;br /&gt;
name = data.get(‘post_name’, ‘’).strip() 수정&lt;br /&gt;
name = data.get(‘post_id’, ‘’).strip()&lt;br /&gt;
title은 []로 시작하면 안 된다.&lt;br /&gt;
‘,’ 가 있으면 안된다. (), &amp;amp;, , 는 된다. &lt;br /&gt;
python wp2md.py wordpress.xml 실행&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;section-1&quot;&gt;포스팅 하기&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://boxersb.github.io/etc/2013/04/03/jekyll-introduction/&quot;&gt;rake 를 알게 된 곳&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;자동화 매크로 (적용하지 않음)
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;http://halryang.net/automation-for-jekyll-posting/&quot;&gt;http://halryang.net/automation-for-jekyll-posting/&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://halryang.net/Insert-Image-easily-to-Jekyll-blog/&quot;&gt;이미지 삽입 매크로&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;웹기반 마크다운 에디터 &lt;a href=&quot;http://prose.io&quot;&gt;prose.io&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sat, 15 Oct 2016 00:00:00 +0900</pubDate>
        <link>http://localhost:4000/2016/10/15/jekyll-blog</link>
        <guid isPermaLink="true">http://localhost:4000/2016/10/15/jekyll-blog</guid>
        
        
        <category>Jekyll</category>
        
      </item>
    
      <item>
        <title>Deep Learning for Neuroimage</title>
        <description>&lt;h1 id=&quot;deep-learning-in-general&quot;&gt;Deep Learning in general&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;Textbook
    &lt;ul&gt;
      &lt;li&gt;Deep Learning Book (Yoshua Bengio) &lt;a href=&quot;http://www.deeplearningbook.org/&quot;&gt;[html]&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Review papers
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2013&lt;/code&gt; Representation learning: A review and new perspectives (Yushua Bengio) &lt;a href=&quot;http://www.cl.uni-heidelberg.de/courses/ws14/deepl/BengioETAL12.pdf&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2014&lt;/code&gt; Deep learning for neuroimaging: a validation study &lt;a href=&quot;http://journal.frontiersin.org/article/10.3389/fnins.2014.00229/full&quot;&gt;[pdf]&lt;/a&gt;
&lt;!--readmore--&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2015 Nature&lt;/code&gt; Deep learning (Yann LeCun, Yoshua Bengio, Geoffrey Hinton) &lt;a href=&quot;http://www.nature.com/nature/journal/v521/n7553/full/nature14539.html&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2015&lt;/code&gt; Deep learning in neural networks: An overview (J. Schmidhuber) &lt;a href=&quot;http://www2.econ.iastate.edu/tesfatsi/DeepLearningInNeuralNetworksOverview.JSchmidhuber2015.pdf&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2016&lt;/code&gt; Understanding deep convolutional networks &lt;a href=&quot;http://rsta.royalsocietypublishing.org/content/374/2065/20150203&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2016&lt;/code&gt; Deep Learning in medical imaging: overview and future promise of an exciting new technique &lt;a href=&quot;http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7463094&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2016.07&lt;/code&gt; Towards an integration of Deep Learning and Neuroscience &lt;a href=&quot;http://biorxiv.org/content/biorxiv/early/2016/06/13/058545.full.pdf&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Network Models
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2012&lt;/code&gt; ImageNet classification with deep convolutional neural networks (A. Krizhevsky et al. Hinton) &lt;a href=&quot;http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2015&lt;/code&gt; Fully convolutional networks for semantic segmentation (J. Long et al.) &lt;a href=&quot;http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Long_Fully_Convolutional_Networks_2015_CVPR_paper.pdf&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2014&lt;/code&gt; Very deep convolutional networks for large-scale image recognition (K. Simonyan and A. Zisserman) &lt;a href=&quot;http://arxiv.org/pdf/1409.1556&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2014&lt;/code&gt; Visualizing and understanding convolutional networks (M. Zeiler and R. Fergus) &lt;a href=&quot;http://arxiv.org/pdf/1311.2901&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2015&lt;/code&gt; Fast R-CNN (R. Girshick) &lt;a href=&quot;http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Girshick_Fast_R-CNN_ICCV_2015_paper.pdf&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2015&lt;/code&gt; Going deeper with convolutions (C. Szegedy et al. Google) &lt;a href=&quot;http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Szegedy_Going_Deeper_With_2015_CVPR_paper.pdf&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2016&lt;/code&gt; Deep residual learning for image recognition (K. He et al. Microsoft) &lt;a href=&quot;http://arxiv.org/pdf/1512.03385&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;CNN
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2013&lt;/code&gt; Decaf: A deep convolutional activation feature for generic visual recognition (J. Donahue et al.) &lt;a href=&quot;http://arxiv.org/pdf/1310.1531&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2014&lt;/code&gt; DeepFace: Closing the Gap to Human-Level Performance in Face Verification (Y. Taigman et al.) &lt;a href=&quot;http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Taigman_DeepFace_Closing_the_2014_CVPR_paper.pdf&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2015&lt;/code&gt; Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks (S. Ren et al.) &lt;a href=&quot;http://papers.nips.cc/paper/5638-faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks.pdf&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2015&lt;/code&gt; Imagenet large scale visual recognition challenge (O. Russakovsky et al.) &lt;a href=&quot;http://arxiv.org/pdf/1409.0575&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2015&lt;/code&gt; &lt;a href=&quot;http://sanghyukchun.github.io/92&quot;&gt;A Neural Algorithm of Artistic Style&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;CNN visuatlization
    &lt;ul&gt;
      &lt;li&gt;Visualizing and understanding convolutional networks &lt;a href=&quot;http://www.cs.nyu.edu/~fergus/papers/zeilerECCV2014.pdf&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;mNeuron: a Matlab plugin to visualize neurons from deep models &lt;a href=&quot;http://vision03.csail.mit.edu/cnn_art/index.html&quot;&gt;[html]&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;Deep visualization toolbox &lt;a href=&quot;https://github.com/yosinski/deep-visualization-toolbox&quot;&gt;[code]&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;3D visualization of a convolutional neural network &lt;a href=&quot;http://scs.ryerson.ca/~aharley/vis/conv/&quot;&gt;[demo]&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;Understanding neural networks through deep visualization &lt;a href=&quot;http://yosinski.com/deepvis&quot;&gt;[html]&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;Convolutional neural networks for visual recognition &lt;a href=&quot;http://cs231n.github.io/understanding-cnn/&quot;&gt;[html]&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2015&lt;/code&gt; Deep Dream: visualizing every layer of GoogLeNet &lt;a href=&quot;http://www.pyimagesearch.com/2015/08/03/deep-dream-visualizing-every-layer-of-googlenet/&quot;&gt;[html]&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2016&lt;/code&gt; Visualization of deep convolutional neural networks &lt;a href=&quot;http://openscholarship.wustl.edu/cgi/viewcontent.cgi?article=1150&amp;amp;context=eng_etds&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Articles
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2016.03&lt;/code&gt; Deep learning in medical imaging: the not-so-near future &lt;a href=&quot;http://www.diagnosticimaging.com/pacs-and-informatics/deep-learning-medical-imaging-not-so-near-future&quot;&gt;[html]&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2016.04&lt;/code&gt; Deep learning used to assist overburdened diagnosticians &lt;a href=&quot;https://www.sciencedaily.com/releases/2016/04/160404134050.htm&quot;&gt;[html]&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2016.08&lt;/code&gt; AI startups in Healthcare &lt;a href=&quot;https://www.cbinsights.com/blog/artificial-intelligence-startups-healthcare/&quot;&gt;[html]&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2016.09&lt;/code&gt; Machine Intelligence in Medical Imaging Conference – Report &lt;a href=&quot;http://n2value.com/blog/machine-intelligence-in-medical-imaging-conference-report&quot;&gt;[html]&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2016.09&lt;/code&gt; The role of AI in Healthcare &lt;a href=&quot;https://www.linkedin.com/pulse/role-ai-healthcare-in-depth-guide-thomas-riisgaard-hansen&quot;&gt;[html]&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2016.09&lt;/code&gt; DeepMind wants its healthcare AI to charge by results - but first it needs your data &lt;a href=&quot;https://techcrunch.com/2016/09/20/deepmind-wants-its-healthcare-ai-to-charge-by-results-but-first-it-needs-your-data/&quot;&gt;[html]&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2016.09&lt;/code&gt; Microsoft announces new AI-powered health care initiatives targeting cancer &lt;a href=&quot;http://www.theverge.com/2016/9/20/12986314/microsoft-ai-healthcare-project-hanover-cancer&quot;&gt;[html]&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2016.09&lt;/code&gt; &lt;a href=&quot;http://fortune.com/ai-artificial-intelligence-deep-machine-learning/&quot;&gt;Why deep learning is suddenly changing your life&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Link
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://github.com/terryum/awesome-deep-learning-papers&quot;&gt;Awesome - Most Cited Deep Learning Papers&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://memkite.com/deep-learning-bibliography/&quot;&gt;Links to Deep Learning Subtopics&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://tensorflowkorea.wordpress.com/2016/04/18/fundamental-of-deep-learning-preview/&quot;&gt;Book: Fundamental of Deep Learning&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://laonple.blog.me/220463627091&quot;&gt;머신러닝 튜토리얼&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Topic
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2016.09&lt;/code&gt; &lt;a href=&quot;http://visla.kr/?p=45671&quot;&gt;인공지능이 작곡한 세계 최초의 음악이 공개되다&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;tensorflow&quot;&gt;TensorFlow&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Tutorials
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;http://tensorflow.org&quot;&gt;TensorFlow 공식 홈페이지&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://github.com/tensorflow/tensorflow/releases&quot;&gt;TensorFlow Github&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://playground.tensorflow.org/&quot;&gt;TensorFlow Playground&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://hub.docker.com/r/imcomking/bi_deeplearning/&quot;&gt;Deep LEarning Docker Image&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://gist.github.com/haje01/202ac276bace4b25dd3f&quot;&gt;텐서플로우 시작하기 (김정주)&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://tensorflowkorea.wordpress.com/&quot;&gt;텐서플로우 코리아&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://tensorflowkorea.wordpress.com/2015/12/04/%ED%85%90%EC%84%9C%ED%94%8C%EB%A1%9C%EC%9A%B0-%ED%8A%9C%ED%86%A0%EB%A6%AC%EC%96%BC-1/comment-page-1/&quot;&gt;텐서플로우 튜토리얼 (텐서플로우 코리아)&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://tensorflowkorea.wordpress.com/2015/12/04/%ED%85%90%EC%84%9C%ED%94%8C%EB%A1%9C%EC%9A%B0-%ED%8A%9C%ED%86%A0%EB%A6%AC%EC%96%BC-1/comment-page-1/&quot;&gt;Book: 텐서플로우 첫걸음&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://hunkim.github.io/ml/&quot;&gt;Lecture: 모두를 위한 딥러닝/머신러닝 강의 TensorFlow (김성)&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://codeonweb.com/course/7e8c4944-308e-410e-85aa-644624613741&quot;&gt;Lecture: TensorFlow 로 시작하는 기계 학습과 딥 러닝 (CodeOnWeb)&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://github.com/bi-lab/deeplearning_tutorial/blob/master/Deep_RL_tensorflow/TensorFlow_Tutorial.ipynb&quot;&gt;TensorFlow Tutorial (SNU BILAB)&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://dsmoon.tistory.com/category/Deep%20Learning/TensorFlow&quot;&gt;Deep learning/TensorFlow (문동선)&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://tflearn.org/&quot;&gt;TFlearn&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Open-source TensorFlow Implementation
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://github.com/tensorflow/models&quot;&gt;Syntax Net, Magenta, Image2Txt&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://github.com/TensorFlowKR/awesome_tensorflow_implementations&quot;&gt;https://github.com/TensorFlowKR/awesome_tensorflow_implementations&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;deep-learning-for-neuroinformatics&quot;&gt;Deep learning for Neuroinformatics&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2015&lt;/code&gt; Deep Neural Networks: a new fraomework for modeling biological vision and brain information processing &lt;a href=&quot;http://www.annualreviews.org/doi/pdf/10.1146/annurev-vision-082114-035447&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;deep-learning-for-neuron-segmentation&quot;&gt;Deep learning for Neuron Segmentation&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Electron Microscopy
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2013&lt;/code&gt; Large-scale automatic reconstruction of neuroanl processes from electron microscopy images &lt;a href=&quot;https://arxiv.org/pdf/1303.7186.pdf&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2016&lt;/code&gt; Deep learning trends for focal brain pathology segmentation in MRI &lt;a href=&quot;https://arxiv.org/pdf/1607.05258.pdf&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;deep-learning-for-brain-tumor-segmentation&quot;&gt;Deep learning for Brain Tumor Segmentation&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;CODE
    &lt;ul&gt;
      &lt;li&gt;ISBI 2012 brain EM image segmentation &lt;a href=&quot;https://github.com/ahmed-fakhry/dive&quot;&gt;[github]&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;Efficient multi-scale 3D convolution neural network for brain lesion segmentation &lt;a href=&quot;https://github.com/Kamnitsask/deepmedic&quot;&gt;[github]&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;MRI
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2012&lt;/code&gt; A comparative study of MRI data using various Machine Learning and pattern recognition algorithms to Detect Brain Abnormalities &lt;a href=&quot;http://crpit.com/confpapers/CRPITV134Singh.pdf&quot;&gt;[pdf]&lt;/a&gt; = A novel machine learning approach for detecting the Brain Abnormalities from MRI structural images &lt;a href=&quot;http://link.springer.com/chapter/10.1007%2F978-3-642-34123-6_9#page-1&quot;&gt;[html]&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2014&lt;/code&gt; Survey of intelligent methods for Brain Tumor Detection &lt;a href=&quot;http://www.ijcsi.org/papers/IJCSI-11-5-1-108-117.pdf&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2015&lt;/code&gt; Brain tumor detection and segmentation in multisequence MRI &lt;a href=&quot;https://www.vutbr.cz/www_base/zav_prace_soubor_verejne.php?file_id=109549&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2015&lt;/code&gt; Automated glioma segmentation in MRI using deep convolutional networks  &lt;a href=&quot;http://www.diva-portal.org/smash/get/diva2:841518/FULLTEXT01.pdf&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2015&lt;/code&gt; Learning with Difference of Gaussian Features in the 3D Segmentation of Glioblastoma Brain Tumors &lt;a href=&quot;http://cs229.stanford.edu/proj2015/277_report.pdf&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2015&lt;/code&gt; Multi-scale 3D convolutional neural networks for lesion segmentation in brain MRI &lt;a href=&quot;http://www.doc.ic.ac.uk/~bglocker/pdfs/kamnitsas2015isles.pdf&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2015&lt;/code&gt; MICCAI-BRATS 2015 proceedings &lt;a href=&quot;http://people.csail.mit.edu/menze/papers/proceedings_miccai_brats_2015.pdf&quot;&gt;[pdf]&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;Structured prediction with convolutional neural networks for multimodal brain tumor segmentation&lt;/li&gt;
          &lt;li&gt;A convolutional neural network approach to brain tumor segmentation&lt;/li&gt;
          &lt;li&gt;Multimodal brain tumor segmentation (BRATS) using Sparse Coding and 2-layer Neural Network&lt;/li&gt;
          &lt;li&gt;Deep convolutional neural networks for the segmentation of gliomas in multi-sequence MRI&lt;/li&gt;
          &lt;li&gt;Brain tumor segmentation with Deep Learning&lt;/li&gt;
          &lt;li&gt;Multi-modal brain tumor segmentation using Stacked Denoising Autoencoders&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2015&lt;/code&gt; Brain tumor detection and classification using deep learning classifier on MRI images  &lt;a href=&quot;http://www.maxwellsci.com/jp/abstract.php?jid=RJASET&amp;amp;no=547&amp;amp;abs=08&quot;&gt;[html]&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2015&lt;/code&gt; Detection and segmentation of brain metastases with deep convolutional networks &lt;a href=&quot;http://www.diva-portal.se/smash/get/diva2:853460/FULLTEXT01.pdf&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2015&lt;/code&gt; Deep Feature Learning with discrimination mechanism for brain tumor segmentation and diagnosis &lt;a href=&quot;http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7415818&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2015 Plos One&lt;/code&gt; Automated glioblastoma segmentation based on a multiparametric structured unsupervised classification &lt;a href=&quot;http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0125143&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2015 CVPR&lt;/code&gt; Deep neural networks for anatomical brain segmentation &lt;a href=&quot;https://www.semanticscholar.org/paper/Deep-neural-networks-for-anatomical-brain-Br%C3%A9bisson-Montana/1689c752d566a2b3bdee46d0b87d7623c66218d0&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2016&lt;/code&gt; Brain Tumor Segmentation Using Convolutional Neural Networks in MRI Images &lt;a href=&quot;http://ieeexplore.ieee.org/document/7426413/?tp=&amp;amp;arnumber=7426413&amp;amp;punumber%3D42&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2016 Stanford Report&lt;/code&gt; A new algorithm for fully automatic brain tumor segmentation with 3D convolutional Neural Networks &lt;a href=&quot;http://cs231n.stanford.edu/reports2016/322_Report.pdf&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2016&lt;/code&gt; On image segmentation methods applied to glioblastoma: state of art and new trends &lt;a href=&quot;https://hal.archives-ouvertes.fr/hal-01325355/document&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2016&lt;/code&gt; Efficient multi-scale 3D CNN with fully connected CRF for accurate brain lesion segmentation &lt;a href=&quot;http://arxiv.org/pdf/1603.05959v2.pdf&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Pathology
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2012&lt;/code&gt; Deep Neural Networks segment neuronal membranes in electron Microscopy images &lt;a href=&quot;http://papers.nips.cc/paper/4741-deep-neural-networks-segment-neuronal-membranes-in-electron-microscopy-images&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;deep-learning-for-brain-tumor-grading&quot;&gt;Deep learning for Brain Tumor Grading&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;MRI
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2015 IEEE EMBS&lt;/code&gt; Brain tumor grading based on neural networks and convolutional neural netsworks &lt;a href=&quot;http://www.ncbi.nlm.nih.gov/pubmed/26736358&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2016 Comput Math Methods Med&lt;/code&gt; Multiscale CNNs for brain tumor segmentation and diagnosis &lt;a href=&quot;http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4812495/pdf/CMMM2016-8356294.pdf&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;PET
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2016&lt;/code&gt; Convolutional neural network can help differentiate FDG PET images of brain tumor between glioblastoma and primary central nervous system lymphoma [&lt;a href=&quot;http://jnm.snmjournals.org/content/57/supplement_2/1855?related-urls=yes&amp;amp;legid=jnumed;57/supplement_2/1855&quot;&gt;html&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Brain pathology images
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2015&lt;/code&gt; Automated grading of gliomas using deep learning in digital pathology images: a modular approach with ensemble of convolutional neural networks &lt;a href=&quot;http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4765616/pdf/2243353.pdf&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Prostate/chest pathology images
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2016 Nature Sci.Rep.&lt;/code&gt; Deep learning as a tool for increased accuracy and efficiency of histopathological diagnosis &lt;a href=&quot;http://www.nature.com/articles/srep26286&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2015&lt;/code&gt; Deep learning with non-medical training used for chest pathology identification &lt;a href=&quot;https://www.cs.tau.ac.il/~wolf/papers/SPIE15chest.pdf&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;section&quot;&gt;딥러닝&lt;/h3&gt;
&lt;p&gt;알파고&lt;/p&gt;

&lt;h4 id=&quot;section-1&quot;&gt;이모지&lt;/h4&gt;
&lt;p&gt;&lt;a href=&quot;http://www.webpagefx.com/tools/emoji-cheat-sheet/&quot;&gt;Emoji Cheat Sheet&lt;/a&gt;
:sparkles: :star: :star2: :two_hearts: :gift_heart:  :boom:&lt;/p&gt;
</description>
        <pubDate>Sun, 09 Oct 2016 00:00:00 +0900</pubDate>
        <link>http://localhost:4000/2016/10/09/deep-learning-for-neuroimage</link>
        <guid isPermaLink="true">http://localhost:4000/2016/10/09/deep-learning-for-neuroimage</guid>
        
        
        <category>Deep Learning</category>
        
      </item>
    
      <item>
        <title>기술은 세상을 바꾸는데, 과학은 어디에 쓰나?</title>
        <description>&lt;h3 id=&quot;section&quot;&gt;기술은 있고 과학은 없다&lt;/h3&gt;
&lt;p&gt;서울공대를 다니면서도 과학은 전혀 몰랐다. 정말 그랬다. 1학년 1학기 공대 공통과목인 일반물리 중간고사에서 세 번째로 높은 점수를 받았다. 그런데도 과학은 몰랐다. 상대성이론도 양자역학도 진화론도 어떠한 종류의 우주론도 배우지 못했다.&lt;/p&gt;

&lt;p&gt;현대는 기술의 시대다. 시대의 아이콘으로 추앙받는 스티브 잡스, 빌 게이츠, 래리 페이지, 일론 머스크는 기술 혁신으로 세상을 바꾼 사람들이다. 한때 신경과학자의 길을 걸었다는 데미스 하사비스를 시대의 아이콘 목록에 추가하더라도 결과는 마찬가지다.&lt;/p&gt;

&lt;p&gt;에트리(ETRI)에서 연구원 생활을 하고 있으면서도 과학 수다를 나눌 기회는 거의 없다. 치열했던 과학 수다는 아마도 150원 짜리 자판기 커피를 뽑아 마시던 시절의 기억이 거의 마지막이다. 우주가 언제 어떻게 생겼는지, 행성 지구에서 생명이 어떻게 출현했는지, 진화를 설명하는 이론에는 어떤 것들이 있는지에 대해서는 일상에서 마주치는 사람들과 이야기를 나눠 본 적이 없다.&lt;/p&gt;

&lt;p&gt;작년에 에트리 ‘새통사(새로운 통찰을 생각하는 사람들)’라는 모임에서 에릭 캔델의 책을 주제로 ‘통찰의 시대: 과학과 예술의 새로운 협력’이라는 강연을 했다. 참석자들과 중국집에서 저녁을 먹으며 3시간 동안 나눈 얘기는 이를테면, 700메가 주파수 대역을 재난용으로 쓸 것이냐 IOT로 쓸 것이냐, 와이브로의 기술적 성공과 시장에서의 실패, 5G와 와이브로의 기술적 유사성, 대한민국 간판을 모두 LED를 바꾸면 어떤 일이 벌어질 것인가, 인공지능 기술의 부침, IBM 왓슨 개발의 역사와 같은 것들이었으니 과연 내가 다니는 연구소가 에트리가 맞구나 싶었던 순간이다. 기술은 있고 과학은 없었다.&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;기술의 시대에 과학을 이야기하는 사람들이 있다&lt;/h3&gt;
&lt;p&gt;10년 전쯤 일이다. 내가 근무하던 에트리 건물 1층에서 백북스(당시 이름은 100권독서클럽) 모임이 2주에 한 번씩 열리고 있었지만 화요일 저녁에 나는 항상 축구를 하러 가야 했다.&lt;/p&gt;

&lt;p&gt;그러던 어느 날, 그날따라 백북스 선정도서 제목이 눈에 들어왔다. &amp;lt;생명 최초의 30억년&amp;gt;이라. 급변하는 세상을 쫓아가기 바빠서 3년 단위로 IT 기술을 개발하는 연구소에서 그토록 한가한 주제라니. 나는 당시만 해도 30억 년이라는 시간을 머릿속에 떠올려 본 적이 없었다. 30억 년 전의 지구에도 생명이 있었구나. 그렇게 나는 백북스에 처음 발을 들여놓았다.&lt;/p&gt;

&lt;p&gt;문화 충격을 제대로 받았다. 내가 한 번도 생각해 본 적이 없는 주제에 대해서 발제를 준비한 백북스 회원은 저자나 역자도 아니며 교수나 박사도 아니었다. 하지만 최소한 석 달 이상을 오로지 그 날의 발표를 위해 산 것처럼 보였다. 열 권도 넘는 책이 참고도서로 언급되었다. 아! 과학을 이토록 신나게 이야기하는 사람들이 있구나.&lt;/p&gt;

&lt;p&gt;백북스(&lt;a href=&quot;100boos.kr&quot;&gt;100books.kr&lt;/a&gt;)는 한일월드컵이 한창이던 2002년 6월, 대전에서 조촐하게 시작됐다. 2주에 한 번, 거르지 않고 14년째 모임을 이어오고 있으며 서울, 인천, 충북, 강화에서도 모임이 열린다. 대전백북스는 인문, 사회, 과학, 예술 등 분야에 치우치지 않고 책을 선정하려고 노력한 탓에 과학책도 꽤 읽었다.&lt;/p&gt;

&lt;p&gt;그리고 2008년이었던가, 서울백북스가 조그만 사랑방에서 출발했다. 대전에서 시작된 독서모임 플랫폼을 서울로 옮겨 심는 작업에 나도 힘을 보탰었다. 한 달에 한 번 모이는 서울백북스는 과학책을 읽기로 작정했고, 지금의 서울백북스는 전국에서 둘도 없는 과학독서 모임이 되었다.&lt;/p&gt;

&lt;p&gt;백북스 외에도 과학을 이야기하는 사람들이 점점 늘어나고 있다. APCTP 크로스로드 웹진과 소백산천문대 행사, ‘서대문자연사박물관’의 시리즈 강연, ‘과학과 사람들’에서 기획한 팟캐스트와 공연들, 과학책을 꾸준히 내는 출판사들,페이스북 그룹 ’과학책 읽는 보통 사람들’에서의 과학책 이야기들이 과학 문화의 토양이 되고 있다. 이제 edge.org나 과학 전문 도서관 설립으로 넘어갈 때가 된 듯하다.&lt;/p&gt;

&lt;h3 id=&quot;section-2&quot;&gt;과학이 대체 무슨 소용이 있길래&lt;/h3&gt;
&lt;p&gt;과학은 지식을 만드는 활동이며 자연을 기술한다. 과학은 물론 기술 개발의 토대를 제공한다. 양자역학을 모르고 트랜지스터는 있을 수 없으며, 상대성이론을 모르고 정교한 GPS는 불가능하다. 과학은 기술의 씨앗과도 같다.&lt;/p&gt;

&lt;p&gt;하지만 과학이 기술 개발에 반드시 필요한 것은 아니다. 기술은 과학 없이도 만들어진다. 18세기 이전에는 사실상 과학 없는 기술의 시대였으며, 지금도 기술이 과학을 앞서곤 한다. 요즘 상한가를 치고 있는 딥러닝 기술은 신경세포의 신호 전달 모델을 모방하여 만든 퍼셉트론에서 출발했지만, 패턴 인식과 추론에 관한 뇌기능의 이해 없이 개척한 결과물이다. 우리는 여전히 뇌에서 어떤 일이 일어나는지 잘 모른다. 어쨌든 딥러닝은 잘 작동한다.&lt;/p&gt;

&lt;p&gt;기술이 과학을 압도하는 시대다. 로봇, 드론, 3D프린터, CRISPR, 머신러닝, 전기 자동차, 자율주행 자동차, 재활용 로켓, 클라우드 컴퓨팅, 양자 컴퓨터.. 현재 알고 있는 과학만으로도 새로운 기술은 쏟아져 나온다.&lt;/p&gt;

&lt;p&gt;이렇게 멋진 기술들이 세상을 바꾸는데, 과학은 태연히 자연을 들여다보기만 한다. CERN의 LHC 가속기, 칠레의GMT 망원경, 슈퍼 카미오칸데 중성미자 검출기, LIGO 중력파 관측소, 인간 게놈 프로젝트처럼 더 깊이 들여다보기 위해 거대 기술을 투입한다.&lt;/p&gt;

&lt;p&gt;힉스 입자를 발견했다. 우주에 존재하는 힘을 입자의 관점에서 기술하려는 시도는 더 많은 지지를 획득한다. 우주의 구성 물질은 무엇으로 이루어질까에 대한 답이 될 수 있다. 이론적인 예측이 실험으로 나타날 때 마지막 퍼즐 조각을 맞추는 듯한 희열마저 느껴진다. 그토록 ‘신의 입자’를 찾아 헤매지 않았던가. 얼마 안 있어 중력파를 발견했다. 아인슈타인이 맞았다. 일반 상대성이론은 우주적인 관점에서 잘 들어맞는다. 인류는 새로운 중력파 안경을 갖게 되었고,전자기파로 관측할 수 없었던 우주가 모습을 드러낼 차례다.&lt;/p&gt;

&lt;p&gt;힉스 입자와 중력파의 발견이 누군가에게는 큰 선물일 수 있다. 하지만 현실 세계에서 어떤 소용이 있을까 여전히 의문이 남는다. 힉스든 중력파든 먹고 살기 바쁜 시대에 웬 과학 같은 한가한 소리인가.&lt;/p&gt;

&lt;h3 id=&quot;section-3&quot;&gt;과학은 이야기를 만들고 생각을 바꾼다&lt;/h3&gt;
&lt;p&gt;스콧 샘슨의 &lt;공룡 오디세이=&quot;&quot;&gt; 일부를 함께 읽어보자.&lt;/공룡&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“문화사학자 토머스 베리는 우리가 지금 직면한 환경위기는 결국 이야기가 없는 탓에 생긴 것이라고까지 말한다. 현재 우리는 인류를 더 큰 맥락에 놓는 흥미로운 이야기를 갖고 있지 못하고, 따라서 우리의 삶에는 의미나 커다란 목적이 결여되어 있다. 이제 우리는 많은 전산업사회의 문화(그리고 현재의 토착문화)에서는 일상적인 것이었던 자연에 대한 경외, 경이로움, 성스러움을 느끼지 못한다. 하지만 새로운 이야기는 어떤 것이어야 할까? 많은 과학자, 신학자,교육자의 지지를 받고 있는 베리의 답은 빅뱅에서 시작해 우여곡절을 거쳐 현재로 이어지는 위대한 이야기(Great Story)다. 때로는 ‘우주 이야기(Universal Story)’, ‘새로운 이야기(New Story)’, ‘진화의 서사시’라고도 불린다. … 어떤 이들은 이 이야기는 과학혁명의 위대한 성취일 뿐 아니라 과학과 종교의 균열을 메우고 우리에게 절실하게 필요한 삶의 의미와 목적의식을 제공한다고 생각한다. 나도 그 중 한 사람이다.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;과학은 이야기를 만든다. 고대 그리스 시대 이전부터 있어 왔던 여러 종류의 신화를 현대의 관점에서 각색하려는 시도라고 보아도 좋다. 과학은 현대 인류가 총력을 기울여 함께 쓰는 대서사시다.&lt;/p&gt;

&lt;p&gt;현대의 세계관이 새롭게 재구성되면 윤리장전도 다시 쓰인다. 특정 기술을 받아들일지 말지 증거를 수집하고 판단 근거를 제시하는 것은 과학의 역할이다. 예컨대 이산화탄소 배출이 지구 온난화를 가속화 하는가, 담배가 폐암을 일으키는 원인이 되는가, 게임이 아이들을 폭력성을 부추기는가와 같은 질문이 던져질 때 과학적 근거에서 답을 찾아야 한다. 자연에 어떠한 변화가 생기는지 지켜보는 것이야말로 과학의 장기가 아니던가.&lt;/p&gt;

&lt;p&gt;과학은 자연을 바꾸지는 않지만, 인류의 생각을 바꾼다. 하긴 우리 생각도 자연이라면 자연이다. 과학은 하나의 세계관이며 새로운 윤리를 위한 공통의 기반이다. 과학은 기술의 혜택을 향유하는 사람들, 기술의 폭력에 피해 받는 사람들 모두가 발 디딜 출발점이 될 수 있다.&lt;/p&gt;

&lt;p&gt;마지막으로, 확고불변한 지식은 없다는 것이 과학이 주는 가장 중요한 메시지다. 우리는 언제든지 생각을 바꿀 준비가 되어 있어야 하고 논리보다는 증거에 의지해야 한다. 새로운 증거가 더해지면 이론을 수정해야 한다. 그것이 우리가 세상에 태어난 첫날부터 세계를 이해하기 위해 활용한 방식이고, 알파고가 바둑을 배우는 방식이며, 과학이 작동하는 방식이다. 과학 지식은 계속 변하고 확장되는데 어제의 과학으로 이해했던 세계가 오늘의 과학으로 이해한 세계와 같을 수 없다. 과학은 어제와 다른 오늘을 요청한다.
&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;아시아태평양이론물리센터(APCTP)에서 발간하는 크로스로드 웹진에 실린 글입니다.&lt;/code&gt;&lt;/p&gt;
</description>
        <pubDate>Sat, 23 Jul 2016 00:00:00 +0900</pubDate>
        <link>http://localhost:4000/2016/07/23/tech-and-science</link>
        <guid isPermaLink="true">http://localhost:4000/2016/07/23/tech-and-science</guid>
        
        
        <category>과학과 예술</category>
        
      </item>
    
      <item>
        <title>알파고는 어떻게 바둑을 둘까</title>
        <description>&lt;p&gt;&lt;a href=&quot;https://brunch.co.kr/@madlymissyou/9&quot;&gt;Brunch에서 발행한 원문&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;section&quot;&gt;바둑은 전쟁, 아니면 땅따먹기&lt;/h3&gt;
&lt;p&gt;바둑은 흑과 백으로 편을 나누어 가로세로 19줄의 보드판에서 승부를 겨루는 게임이다. 흑과 백은 서로 얽혀 싸우기도 하고 적절한 선에서 경계를 만들고 사이좋게 땅을 나누기도 한다. 그런데 바둑에서 승부를 가르는 방법은 간단하지 않다. 바둑이 전쟁을 본 따서 만든 것이라면 반상(전쟁터) 위에 남은 돌(병사)을 세어 승부를 결정할 것이고, 바둑을 땅따먹기로 본다면 돌(기둥)로 둘러싼 공간(집)이 큰 쪽이 이기게 될 것이다.&lt;/p&gt;

&lt;p&gt;전쟁으로서의 바둑을 채택한 것이 중국 규칙이고, 땅따먹기로서의 바둑을 채택한 것이 일본 규칙이다. 중국에서는 바둑판 위에 살아 있는 돌이 많으면 이긴다. 일본과 한국에서는 집이 많은 쪽이 이긴다. 이러한 관점의 차이는 특수한 상황에서 돌의 생사가 달라지기도 하며, 끝내기 계산에서 미묘한 차이를 만들어 내기도 한다.
알파고와 이세돌 9단의 시합은 중국 규칙으로 치러진다. 걱정할 필요는 없다. 이세돌 9단은 중국 프로 리그 경험이 있는 국제적인 기사다. 반면에 알파고는 일본 규칙으로 바둑을 둘 수 없다. 중국 규칙으로 학습되어 있으니 심각한 오류를 출력할 수 있다.&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;바둑은 운보다 실력&lt;/h3&gt;
&lt;p&gt;빈 바둑판을 마주한 플레이어에게는 무한한 자유가 주어진다. 선택지가 많다는 뜻이다. 또 바둑은 포커나 고스톱과 달리 모든 정보가 쌍방에게 공개된다. 바둑에 히든카드는 없다. 카드게임이나 주사위 게임처럼 바둑통에서 점수가 높은 돌을 뽑을 수 있는 것도 아니다. 모든 돌은 평등하다.&lt;/p&gt;

&lt;p&gt;바둑에서의 승부는 운보다는 실력으로 가려진다. 그래서 핸디캡(접바둑)으로 균형을 맞춘다. 이세돌 9단이 알파고의 기보를 보고 두 점 아래로 본다고 하는 것은, 알파고가 두 점을 먼저 놓아야 승부가 된다는 말이다. 경기 규칙대로 호선(실력이 동등하여 흑백을 번갈아 두며 먼저 두는 흑의 이득을 상쇄하기 위해 백에게 덤으로 7.5집을 준다)으로 대결할 때 이세돌의 승률은 90% 이상일 것으로 보인다. 물론 5개월 전 판후이와 대결했던 알파고에 해당하는 얘기다.&lt;/p&gt;

&lt;h3 id=&quot;section-2&quot;&gt;패러다임의 전환&lt;/h3&gt;
&lt;p&gt;2천 년이 넘는 바둑의 역사에서 두 번의 패러다임 변화가 있었다. 변혁의 시기에 등장한 새로운 이론은 기존의 이론을 압도했다. 하수가 고수를 이기지 못하듯, 오래된 이론은 새로운 이론에게 상대가 되지 않았다. 바둑은 진화한다.&lt;/p&gt;

&lt;p&gt;기원 전부터 17세기 이전까지의 바둑은 힘바둑 패러다임에 의존해왔다. 바둑을 부분과 부분의 합으로 보고 전투와 전투의 연속으로 보았던 시대다. 힘바둑 패러다임에서는 부분적인 수법과 수읽기 싸움이 중요했다. 이 때의 바둑은 전쟁의 모형이었고 돌의 사활이 중요했다.&lt;/p&gt;

&lt;p&gt;근대 바둑은 구조주의 패러다임와 함께 17세기의 명인 도우사쿠에 의해서 시작되었다. 구조주의에서 전체는 부분의 합 이상이며 전체가 부분을 결정한다. 비로소 한 판의 바둑이라는 관점, 전국적인 시각이 생겼다. 싸움이 아니라 집이 중요하고 돌의 효율이 중요하다. 돌의 능률을 따지기 위해 수나누기라는 계산법이 제안되었다.&lt;/p&gt;

&lt;p&gt;현대 바둑은 신포석 패러다임. 20세기 초 우칭위엔이 열었다. 신포석의 핵심은 중앙의 발견이다. 귀나 변을 중시했던 구조조의에서는 중앙을 등한시 했던 것이다. 우칭위엔은 중앙에서의 세력을 적극적으로 활용하였고, 승률로 증명했다. 포석에서 4선의 착수가 많아졌다. 구조주의에서 신포석으로의 전환을 일컬어 조훈현 9단은 “고전주의가 저물고 낭만주의가 시작되었다”고 표현하기도 했다. 견고한 땅에 지어진 비율 좋은 건축물이 아니라 힘과 역동성을 추구하는 현대 바둑과 비교하니 적절한 비유다.&lt;/p&gt;

&lt;p&gt;‘개체 발생은 계통 발생을 반복한다’라는 속설이 있다. 생물학에서는 오해로 밝혀지긴 했지만, 경험적으로 바둑에서도 이러한 양상이 관찰된다. 바둑을 처음 배울 때 단수부터 배운다. 그 다음에는 축, 장문, 패, 환격, 촉촉수, 회돌이를 배운다. 부분적인 수싸움과 기본적인 사활이 재밌기도 하다. 이때의 바둑에서는 상대방의 곤마(두 집 없이 떠도는 말)를 쫓을 때 기어이 잡겠다는 각오로 달려든다. 포석을 익히고 기력이 늘면 돌의 효율과 분배를 생각하게 된다. 구조주의로 접어든 것. 이때의 바둑에서 상대방의 곤마를 쫓을 때는 반드시 잡으려고 하지 않는다. 곤마를 쫓는 척 하면서 퇴로를 따라 형성되는 집, 그러니까 실제로는 잿밥에 관심이 있는 것이다. 기력이 더 늘면 또다시 새로운 세상을 만나게 된다. 두터움. 후지사와 슈코 9단은 “바둑을 안다는 것은 두터움을 아는 것”이라고 했다. 신포석에서 강조하는 중앙과 세력이 전체 반상에 미치는 영향력, 당장 집으로 환산되지는 않지만 장기적으로 판에 미치는 영향력이 두터움이다. 두터움은 부분이 아니라 전체에 영향을 미친다. 두터움은 공간과 형상에 대한 감각이다. 두터움은 현대 바둑에서 가장 중요한 개념이다. 두터움에 대한 이해 없이는 고단자의 반열에 오를 수 없다.&lt;/p&gt;

&lt;h3 id=&quot;section-3&quot;&gt;바둑은 모양 싸움&lt;/h3&gt;
&lt;p&gt;반상(盤上)은 흑과 백이 춤을 추는 형상의 세계다. 바둑이 전쟁이든 땅따먹기든 중요한 것은 돌과 돌의 연결이다. 홀로된 돌은 살아남을 수도 없고 집을 만들 수도 없다. 연결은 바둑의 기본이며, 돌과 돌이 연결되는 형태가 모양이다.&lt;/p&gt;

&lt;p&gt;수읽기 없이 모양으로만 바둑을 둘 수 있다. 아마추어들의 바둑은 종종 30분 내로 끝나기도 한다. 깊은 수읽기 없이 거의 모든 수를 모양으로 두었다고 보면 된다.
돌을 연결할 때는 두 가지 장점을 모두 살려야 한다. 튼튼하면서도 날렵하게. 균형점을 찾는다면 효율적인 행마가 나온다. 호구, 한 칸 뜀, 날일자와 같이 모양 좋은 연결은 대개 효율이 좋다. 두터움은 힘이 좋은 모양에서 나온다.&lt;/p&gt;

&lt;p&gt;모양이 좋지 않은 우형(愚形)의 대표적인 예는 빈삼각이다. 빈삼각은 기역자로 튼튼하게 꼬부린 형태인데 좁은 공간에 돌이 중복되어 효율이 좋지 않고, 튼튼히 연결될지언정 뻗어나감이 없어 힘이 좋다고도 할 수 없는 모양이다. 입문자에게는 빈삼각을 두지 못하도록 가르친다.&lt;/p&gt;

&lt;p&gt;그런데 가끔은 나쁜 모양이 묘수가 되기도 한다. 대개의 경우 빈삼각은 악수. 하지만 “빈삼각에 묘수 있다”. 빈삼각이 되는 자리라면 평소에는 일감에서 배제되는데, 가끔가다 빈삼각이 묘수가 되기도 한다. 조훈현 9단은 1988년 제1회 응씨배 준결승에서 린하이펑 9단을 상대로 한 판에 세 번의 빈삼각을 두고 승리했다. 승부를 위해서는 좋지 않은 모양도 기꺼이 둘 각오가 되어 있어야 한다.&lt;/p&gt;

&lt;h3 id=&quot;section-4&quot;&gt;바둑 고수가 된다는 것&lt;/h3&gt;
&lt;p&gt;바둑은 운보다 실력이다. 바둑을 잘 두려면 수읽기, 감각, 평정심을 고루 갖춰야 한다. 불확실한 상황에서 여러 시나리오를 미리 그려보고 수순을 정확히 읽어내는 것(수읽기), 서로 다른 형태의 돌이 가지는 가치의 무게를 저울질하고 우선순위를 정하는 것(감각), 상대의 심리를 흔들고 상대의 도발에 흔들리지 않는 것(평정심)이 모두 중요하다.&lt;/p&gt;

&lt;p&gt;수읽기는 특히 부분적인 전투나 끝내기에서 유용하다. 여러 시나리오를 머릿속에서 상상으로 진행할 수 있어야 한다. 컴퓨터의 램에 해당하는 작업기억과 논리적인 추론이 요구된다.&lt;/p&gt;

&lt;p&gt;감각은 형태와 모양에 대한 것, 추상적인 것이다. 프로기사들은 다음 착수할 곳을 한 눈에 두세 곳으로 압축한다. 반상의 모든 경우의 수를 계산할 수는 없는 노릇. 사람은 우선 감각으로 착점할 곳의 후보를 빠르게 추린다. 한 눈에 들어오는 큰 자리를 일감이라고 한다. 하수들의 바둑은 지나치게 일감에 의존한다. 대개 습관적으로 익숙한 모양을 만드는 수준이다. 하수들의 일감은 정답이 아니다. 세련된 감각이 필요하고 수읽기도 필요하다.&lt;/p&gt;

&lt;p&gt;평정심에 관해서는 한마디로 ‘반외팔목(盤外八目)’이라 하겠다. 바둑판 밖에서 보면 8집이 더 유리하다는 뜻이다. 감정은 원래 빠르게 판단하고 행동하기 위해 진화한 것이나 바둑에서는 대체로 무용하다. 이전에 두었던 수가 아까워서 작전을 고집하거나, 당했다는 느낌에 발끈해서 무리한 수를 두게 되는 경우에 바둑을 그르친다. 감정에 휩싸이지 않으면 형세 판단이나 수읽기가 더 정확하다. 감정의 소용돌이에서 자유로운 알파고가 과연 얼마나 유리하다고 보아야 할지는 애매하지만, 첫 판 패배 이후 감정적으로 흔들린 판 후이 2단에게 핸디캡으로 작용한 것만은 분명하다.&lt;/p&gt;

&lt;h3 id=&quot;section-5&quot;&gt;사람처럼 두는 알파고&lt;/h3&gt;
&lt;p&gt;컴퓨터는 계산이 뛰어나다. 하지만 체스와 달리 바둑은 천문학적인 경우의 수를 다룬다. 사람은 감각으로 세 곳 정도의 후보를 추리고 그 경우에 대해서만 수읽기를 한다. 하지만 알파고는 모양을 보고 판단하는 능력, 감각을 지니지 못했다.&lt;/p&gt;

&lt;p&gt;알파고가 기존의 인공지능 바둑 프로그램과 가장 크게 다른 점은 사람의 감각을 학습하는데 뛰어나다는 점이다. 계산 기계인 컴퓨터가 어떻게 감각을 모방할까. 알파고는 기보 16만 건에 나타난 3천만 수를 학습했다. 사람은 대개 모양을 해치지 않으려 애쓴다. 대부분의 바둑은 그럴듯한 모양으로 진행된다. 알파고는 입력된 대국을 통해 자연스럽게 모양에 익숙해 진 것이다.&lt;/p&gt;

&lt;p&gt;판 후이 2단은 알파고와 대국 후에 “사람들이 얘기해주지 않았다면 약간 특이하지만 아주 강한 기사와 대국을 하고 있다고 생각했을 것”이라고 했다. 중국랭킹 1위 커제 9단은 “어느 쪽이 인공지능인지 알 수가 없었다”고 했다. 이 대목에서 뭔가 연상되는 것이 있지 않은가. 알파고는 인공지능 바둑 프로그램 최초로 튜링 테스트를 통과한 것이다. 튜링 테스트는 기계의 행동을 사람과 구분할 수 없을 때 기계가 생각한다고 말할 수 있다는 기준을 제시한 시험 방법이다. 게다가 알파고는 인공지능 바둑 프로그램이 패싸움이나 사석작전을 할 수 없을 거라는 편견도 깼다. 알파고는 사람처럼 바둑을 둔다.&lt;/p&gt;

&lt;p&gt;컴퓨터처럼 바둑을 두는 사람도 있다. 전성기 시절 이창호 9단의 바둑이 그랬다. 상대의 도발에 좀처럼 말려들지 않고 답답하다 싶을 정도로 안정적인 국면을 운영하여 돌부처라 불리던 이창호 9단. 특히 끝내기 계산은 신의 경지로 여겨졌다.
이세돌 9단은 이창호 9단과는 전혀 다른 바둑을 둔다. 수읽기에 강한 이세돌 9단은 유리한 상황에서도 모험을 감수한다. 오죽하면 이세돌 9단의 자서전 제목이 ‘판을 엎어라’겠는가. 이세돌 9단은 안정적이기보다는 모험적이며 창의적이다. 다른 프로기사들도 예상하지 못한 수로 판을 흔드는 것이 특기다. 창의성이야말로 컴퓨터가 아닌 사람에게만 있는 능력으로 여겨진다. 이세돌 9단은 가장 인간다운 바둑을 두는 기사다.&lt;/p&gt;

&lt;p&gt;알파고는 뛰어난 하드웨어로 무장한 컴퓨터 프로그램이다. 컴퓨터처럼 바둑을 두는 인간과의 승부와 창의적인 수로 변화무쌍한 국면을 만들어내는 인간과의 승부 중 어느 쪽이 더 흥미로울까.&lt;/p&gt;

&lt;h3 id=&quot;section-6&quot;&gt;알파고는 바둑을 어떻게 배웠을까&lt;/h3&gt;
&lt;p&gt;바둑의 진행은 트리 구조로 표현할 수 있다. 한 수를 선택하면 또 다른 선택이 이어진다. 트리 구조로 표현되는 모든 경우의 수를 대국 종료 순간까지 시뮬레이션 하고 승패를 미리 보고 올 수 있다면 필승의 수순을 발견할 수 있다. 하지만 바둑에서 이것은 불가능하다. 경우의 수가 현재의 컴퓨터 계산 용량을 넘어 선다. 그래서 알파고를 비롯한 기존의 바둑 프로그램은 트리 중 일부를 무작위로 탐색하여 시뮬레이션 하여 승률을 추정하는 방법을 쓴다. 방송국에서 TV 프로그램 시청률을 집계하기 위해 일부 가구만 조사하는 것과 같은 이치다. 이러한 방식을 몬테카를로 트리 서치(MCTS)라 한다. 하지만 이런 정도의 방법으로는 프로 바둑 수준에 이르지 못한다.&lt;/p&gt;

&lt;p&gt;[그림 1 ] 몬테카를로 트리 서치. 가상 대국을 진행하여 각 수순의 승률을 추정한다. [1]&lt;/p&gt;

&lt;p&gt;알파고는 몬테카를로 트리 서치를 좀더 효율적으로 하기 위해 네 개의 신경망(神經網)을 활용했다. 크게는 두 종류다. ‘정책망’은 몬테카를로 트리 서치를 수행할 때 사람처럼 다음 착점의 후보를 빠르게 선별하기 위한 것이고, ‘가치망’은 매 경우마다 승률을 정확하게 추정하여 형세를 판단하기 위한 것이다. 알파고가 다른 인공지능에 비해 월등히 뛰어난 이유는 정책망과 가치망이 시뮬레이션에 비약적인 효율 개선을 가져왔기 때문이다.&lt;/p&gt;

&lt;p&gt;알파고는 몇 가지 간단한 규칙이 입력된 ‘롤아웃’ 정책망, 아마추어 6~9단의 실력자들이 둔 바둑 16만 건으로 공부한 ‘지도학습’ 정책망, 가상의 바둑을 무수히 진행한 다음 좋은 결과만을 익힌 ‘강화학습’ 정책망 학습을 거치며 단계적으로 실력이 향상된다. 마치 학생들이 수학을 배울 때 공식을 외우고, 연습 문제를 푼 뒤, 스스로 증명에 도전하는 방식과 닮았다.&lt;/p&gt;

&lt;p&gt;정책망의 핵심은 지도학습이다. 지도학습 정책망은 사람의 바둑으로 연습문제 풀이를 하는 것이다. 구글 딥마인드 개발자들은 알파고에게 16만 건의 기보를 던져 주고 그 안에 나타난 3천만 착점을 익히도록 했다. 알파고가 사람처럼 둘 수 있는 것은 지도학습 정책망이 효과적으로 작동하기 때문이다.&lt;/p&gt;

&lt;p&gt;사람은 모양 좋은 행마를 격언으로 배운다. 붙이면 젖혀라, 젖히면 뻗어라, 궁하면 붙여라, 2립3전, 2선은 패망선, 모자는 날일자로 벗어라 등이 모두 행마와 모양에 대한 격언이다. 하지만 알파고에게는 이런 가르침을 주지 않았다. 알파고는 많이 보았기 때문에 저절로 안다. 사람처럼 두려다 보니 모양을 익히게 돈 것이다. 알파고는 KGS 온라인 대국 사이트를 이용한 16만 명의 고수들(아마추어 6단~9단)을 스승으로 둔 셈이다.&lt;/p&gt;

&lt;p&gt;하지만 아마 최고수 10명이 머리를 맞대도 프로 기사 한 명을 이기기 힘들 듯이 16만 명의 의견을 종합한다고 최선의 수가 나온다는 보장이 없다. 그래서 알파고는 배운 것을 하나하나 따져보고 검증하는 ‘강화학습’을 한다. 수천 만 가상 대국을 두면서 어떤 수가 좋은 결과를 가져오는지 배운다.&lt;/p&gt;

&lt;p&gt;학생들이 공부한 결과가 뇌의 시냅스가 재조직되거나 재연결되면서 저장되듯이, 알파고의 학습 결과는 네 개의 신경망에 각 노드의 연결 강도가 조정되는 형태로 저장된다. 알파고가 바둑을 학습하는데 필요한 시간은 4주 정도였다. 알파고는 기보를 좋아하기로 유명한 박영훈 9단이 보았다는 15만 건보다 많은 분량을 4주 만에 학습할 정도로 말랑말랑한 머리를 가졌다. 4주 동안 배운 바둑으로 유럽 챔피언 판 후이 2단을 꺾은 것이다.&lt;/p&gt;

&lt;p&gt;[그림] (a) 가치망으로 추정한 각 착점의 승률 (d) 지도학습 정책망으로 사람의 다음 수를 예측값 (f) 최선의 수순 [1]&lt;/p&gt;

&lt;h3 id=&quot;section-7&quot;&gt;알파고는 첫 수를 어떻게 둘까&lt;/h3&gt;
&lt;p&gt;바둑의 초반 진행을 포석(布石)이라고 한다. 인공지능에게 가장 어려운 것이 포석이다. 알파고는 판후이 2단과 진행한 공개 대국에서 흑이든 백이든 다섯 번 모두 첫 수를 화점(花點)에 놓았다. 어쩌면 알파고의 첫 수는 화점으로 정해져 있는지도 모른다. 빈 바둑판에서 시뮬레이션을 하거나 형세 판단을 하기는 어렵기 때문이다. 현대 바둑에서 화점으로 시작하는 포석이 승률이 높다는 통계에 근거한 결정일 수도 있고, 알파고가 학습한 16만 건의 기보에 화점이 많이 나타났을 수도 있다. 첫 수만이 아니라 초반 몇 수 포석까지 시뮬레이션과 형세 판단 없이 16만 기보에서 가장 많이 등장한 형태로 둘 가능성이 크다. 첫 수와 초반 포석에서 알파고가 착수하는 시간 간격을 보면 힌트가 될지 모르겠다.&lt;/p&gt;

&lt;h3 id=&quot;section-8&quot;&gt;알파고는 다음 한 수를 어떻게 결정할까&lt;/h3&gt;
&lt;p&gt;대국이 진행되면 알파고는 매 수마다 복잡한 결정 과정을 거친다. 사람은 직감에 따라 빠르게 둘 때도 있고 수읽기를 거듭하며 장고하기도 한다. 사람이라면 당연한 필순도 알파고는 매번 충분한 시간을 들여 수읽기를 해야 한다.&lt;/p&gt;

&lt;p&gt;수읽기는 가능한 수순을 탐색하는 것인데, 몬테카를로 트리 서치를 효율적으로 하기 위하여 정책망과 가치망을 활용한다. 정책망은 몇 가지 수로 다음 진행을 압축하고, 가치망은 각 수의 승률을 보다 정확하게 추정한다[그림 2, a]. 정책망과 가치망은 각각 모양과 형세를 보는 사람의 감각에 해당하고, 몬테카를로 트리 서치 시뮬레이션은 수읽기에 해당한다. 수읽기가 끝나면 알파고는 쌍방 최선의 수순을 예측하여 진행한다.&lt;/p&gt;

&lt;p&gt;재밌는 장면이 있다. 판 후이 2단과의 대국[그림 2(f)]에서 알파고는 흰색 네모의 자리를 판 후이 2단의 다음 수로 보고 이후 진행을 번호의 수순으로 예측했다. 이는 쌍방 승률이 높은 수를 두었을 때 나오는 수순이다. 하지만 실전에서 판 후이 2단은 백1의 자리에 두었는데, 대국 후에 판 후이 2단은 실전보다 알파고가 예측한 곳이 더 나은 자리였음을 인정했다.&lt;/p&gt;

&lt;p&gt;반면에 30초 안에 무조건 한 수를 두는 방식으로 진행된 판 후이 2단과의 비공식 대결에서 알파고가 두 번을 진 것은 충분히 시뮬레이션하지 못했기 때문으로 보인다. 하지만 얕은 수읽기와 정책망과 가치망에 의존하여 3승을 거둔 것을 보면 알파고의 감각도 프로 기사 못지 않은 것 같다. 16만 선생의 가르침이 헛되지 않았다.
알파고가 이세돌과의 대국에서 하드웨어를 보강한다면 동일한 제한시간 내에 더 많은 시뮬레이션이 가능할 것이다. 하지만 하드웨어를 늘린다고 실력이 무한정 늘지는 않는다. 고수의 반열에 오르고서도 최고수가 되기까지는 시간이 오래 걸리는 법이다.&lt;/p&gt;

&lt;h3 id=&quot;section-9&quot;&gt;알파고는 동일한 장면에서 똑같이 둘까&lt;/h3&gt;
&lt;p&gt;알파고는 정책망과 가치망을 혼합하여 몬테카를로 트리 서치로 시뮬레이션 하고 가장 승률이 높은 수순을 택한다. 한 번 학습을 하고 나면 대국 중에 정책망과 가치망이 변하진 않는다. 하지만 몬테카를로 트리 서치는 무작위적인 요소가 있으므로 매번 똑같을 수는 없다. 하지만 몬테카를로 트리 서치가 효과적인 이유는 그것이 통계적으로 최적의 결과를 내기 때문이다. 이론적으로는 다르게 둘 여지가 있다 하더라도, 실질적으로 알파고는 동일한 장면에서 대부분 같은 수를 둘 것으로 보인다.
그러한 징후를 판 후이 2단과의 3국과 5국에서 볼 수 있다. 판 후이 2단은 흑을 잡고 둔 3국과 5국에서 동일하게 미니중국식 포석을 선택했다. 백을 잡은 알파고는 흑의 진행에 동일하게 응수했다. 변화가 생긴 것은 판 후이 2단에 의해서였다. 흑21의 자리를 다르게 둔 것. 판 후이 2단은 [참고도 3]의 흑21로 또 한 판의 바둑이라고 보았던 것 같다.&lt;/p&gt;

&lt;p&gt;[참고도 3] 알파고 vs. 판 후이 2단 3국(좌)과 5국(우). 흑을 잡은 판 후이 2단은 흑19까지 동일한 포석을 시도했고 알파고는 백20까지 똑같이 응수했다.&lt;/p&gt;

&lt;h3 id=&quot;section-10&quot;&gt;알파고는 의외로 계산에 약하다&lt;/h3&gt;
&lt;p&gt;부분적인 전투나 사활 문제에서는 수읽기 싸움이다. 그런데 판 후이 2단과의 두 번째 대국에서 알파고는 사활 문제를 실수했다. 판 후이 2단의 돌을 잡을 수 있는 상황에서 모양 좋게 받다가 살려주고 만 것이다. [참고도 4(좌)]의 장면에서 흑으로 둔 수(노란색 세모)는 모양 좋은 일감이지만 [참고도 4(우)]처럼 두었으면 백 다섯은 두 집을 낼 방도가 없다.&lt;/p&gt;

&lt;p&gt;알파고는 다섯 번째 대국에서도 자신의 사활이 걸린 장면에서 실수를 한다. [참고도 5]에서 백54와 흑55의 교환은 명백한 잘못이다. 이 교환이 없었다면 좌변 백돌은 살아 있지만 교환 이후 생사가 불투명하게 되었다. 결국 판 후이 2단이 추궁하여 좌변 백이 갈라지고 쫓기는 신세가 되었다.&lt;/p&gt;

&lt;p&gt;[참고도 4] 알파고 vs. 판 후이 제2국. (좌) 알파고의 실수(노란색 세모). 좌하귀 백 다섯 점이 두 집을 내고 살게 된다. (우) 흑1로 두면 좌하귀 백 다섯 점은 잡혔다&lt;/p&gt;

&lt;p&gt;[참고도 5] 알파고 vs. 판 후이 5국. (좌) 백54(알파고)와 흑55 교환이 알파고의 결정적인 실수. 살아 있던 좌변 백돌의 생사가 불투명 해졌다. (우) 쫓기는 신세&lt;/p&gt;

&lt;h3 id=&quot;section-11&quot;&gt;알파고가 보인 프로의 감각&lt;/h3&gt;
&lt;p&gt;사활 장면에서 보인 두 번의 실수와는 대조적으로 알파고가 프로급 감각으로 맥을 짚어낸 장면도 있었다. 목진석 9단이 바둑TV에서 기보를 해설하며 감탄했던 장면이다. [참고도 6] 백58 이후에 백64로 붙여간 것이 상당히 좋은 맥이었다. 백64에 판 후이 2단이 [참고도 7(좌)] 흑1로 순순히 받아준다면 이후 백12까지의 진행으로 백 우변 세력이 상당히 커진다. 이것은 상변 백 다섯 점을 주는 대가로 세력을 얻는 이른바 사석 작전(일부 돌을 희생하면서 더 큰 이익을 취하는 것)으로 볼 수 있는데, 알파고가 이러한 장면을 의도했다면 프로급 감각을 갖춘 것으로 보인다. 판 후이 2단이 이에 반발하여 실전에서는 [참고도 7(우)]처럼 진행되었는데 상변 흑집을 파괴하여 알파고도 불만이 없다.&lt;/p&gt;

&lt;p&gt;[참고도 6] 알파고 vs. 판 후이 2단 제 5국. 알파고의 맥점. 사석 작전을 염두에 두고 붙인 프로급 감각.&lt;/p&gt;

&lt;p&gt;[참고도 7] 알파고 vs. 판 후이 5국. (좌) 사석 작전으로 진행되었을 때의 장면 (우) 판 후이 2단의 반발로 진행된 실전.&lt;/p&gt;

&lt;h3 id=&quot;section-12&quot;&gt;알파고의 끝내기 실력&lt;/h3&gt;
&lt;p&gt;알파고의 끝내기 실력에 대해서는 정보가 거의 없다. 판후이 2단과의 대국에서 대부분 불계승을 거뒀기 때문이다. 복잡한 패가 남아있거나 사석을 활용할 뒷맛이 남아 있는 상황이 되면 알파고의 실력을 보게 될 것이다.&lt;/p&gt;

&lt;p&gt;끝내기로 가면 경우의 수가 줄어 계산이 가능할 것이라고 생각하기 쉽다. 하지만 알파고가 끝내기를 이창호 수준으로 할 수 있을 것이냐 하면 대답하기 쉬운 문제가 아니다. 끝내기라고 만만하게 보면 안 된다. 알파고는 초중반부터 이미 경우의 수를 효과적으로 줄여 왔다. 그렇지 못했다면 알파고는 다른 인공지능 바둑 프로그램처럼 이세돌에게는 4점 정도 뒤지는 실력에 머물렀을 것이다. 끝내기 상황에서도 반상에 빈 곳은 여전히 많고 변화도 많다. 알파고가 아무리 계산을 잘 해도 끝내기에서 이창호를 능가하기는 어렵지 않을까.&lt;/p&gt;

&lt;h3 id=&quot;section-13&quot;&gt;알파고가 엉뚱한 수에 말려들까&lt;/h3&gt;
&lt;p&gt;많은 사람들이 또한 이세돌이 엉뚱한 수를 두면 예상치 못한 알파고가 실수할 가능성이 있다고 생각하는 듯하다. 예컨대 첫 수를 천원에 놓으면 알파고가 혼란에 빠질 것으로 기대하는 것이다. 하지만 알파고에게 예상치 못한 수가 무엇일까. 알파고는 사람과 달리 예상을 하지 않는다. 그때그때 주어진 상황을 입력하고 정책망과 가치망을 동원하여 시뮬레이션을 돌려볼 뿐이다.&lt;/p&gt;

&lt;p&gt;프로 기사들의 랭킹 시스템으로 Elo 레이팅이라는 것이 있다. 알파고의 Elo 레이팅은  3140점인데 이는 세계 랭킹 283위에 해당하는 실력이다. 판 후이 2단은 3085점(랭킹 371)로 알파고보다 아래다. 알파고와 이세돌(3527점)의 Elo 레이팅 점수 차이는 387점이다. 대략 승률 90% 안팎이다. 알파고는 열 판에 한 판 정도 이세돌을 이길 수도 있는 실력이다. 아무리 인공지능이라도 엉뚱한 수는 가볍게 무시하거나 호되게 응징할 것이다.&lt;/p&gt;

&lt;p&gt;궁금하긴 하다. 하지만 이세돌 9단이 악수를 두어가면서까지 알파고를 테스트할 의도가 있을지 모르겠다. 이세돌 9단으로서는 한 판도 지고 싶지 않을 테고 최선의 기보를 남기려 할 것이다. 이세돌이 자신의 저서 &lt;판을 엎어라=&quot;&quot;&gt;에서 남긴 명언이 있다. “바둑의 끝이 어디인지는 모르지만, 내가 가장 완벽한 수를 두고 상대도 가장 완벽한 수를 둔 바둑에서 승리하고 싶다.”&lt;/판을&gt;&lt;/p&gt;

&lt;p&gt;알파고와 기존 바둑 프로그램의 Elo rating [1]&lt;/p&gt;

&lt;h3 id=&quot;section-14&quot;&gt;알파고는 예절을 갖춘다&lt;/h3&gt;
&lt;p&gt;프로 기사들은 승부가 기울었다 싶으면 돌을 던진다. 몇 집이라도 확실하게 졌다고 생각하면 불계패를 선언하기도 한다. 패배의 순간을 스스로 결정짓는 것이 최선을 다하지 않는 것처럼 보이기도 하지만, 바둑에서는 일종의 예절이다. 상대방의 실수를 기다리며 판을 끌고 가기 않고 돌을 던지고 복기를 하는 것이 보통이다.&lt;/p&gt;

&lt;p&gt;그렇다면 알파고는 어떨까. 판 후이와의 공식 대국에서는 알파고가 5:0으로 전승했기 때문에 알파고의 예절을 확인할 수 없었지만, 비공식 대국에 힌트가 있다. 알파고는 판 후이 2단과 대결한 다섯 판의 비공식 대국에서 두 판을 졌는데 그중 한 판은 불계패로 기록되어 있다. 알파고는 예절까지 학습한 것으로 보인다.&lt;/p&gt;

&lt;h3 id=&quot;vs---&quot;&gt;인류 집단지성 알파고 vs. 인간계 최고수 이세돌&lt;/h3&gt;
&lt;p&gt;인공지능 알파고와 이세돌 9단의 대국을 인간에 대한 기계의 도전으로 보아야 할까.
알파고는 뛰어난 하드웨어로 무장한 컴퓨터 프로그램이다. 하지만 알파고는 집단지성이기도 하다. 알파고는 16만 명의 기보에서 평균을 취하여 그들의 감각을 습득했다. 집단지성의 힘은 세다. 어떤 사람의 키나 나이, 몸무게를 추정할 때 여러 사람의 의견을 평균 내면 꽤 정확하게 맞는다. 알파고의 바둑은 이러한 전략을 따른다. 그래서 무척 사람 냄새가 난다.&lt;/p&gt;

&lt;p&gt;최근 딥드림(Deep Dream)이나 쿨리타(Kullita)처럼 그림이나 음악을 창작하는 인공지능에 사람들이 크게 놀라는 이유는 예술이야말로 인간 고유의 영역이라고 생각했기 때문이다. 과연 바둑에도 인간 고유의 창의성이 남아 있을 것인가. 알파고가 하나의 주체로서 한 판의 바둑을 창조할 수 있을까.&lt;/p&gt;

&lt;p&gt;알파고에게 우리가 흔히 기풍이라고 부르는 일관된 스타일은 없을 지도 모른다. 하지만 기풍의 유무나 이세돌 9단과의 승부와는 무관하게, 알파고는 집단지성의 힘을 빌어 탄생한 인류의 위대한 성취로 기록될 것이다.&lt;/p&gt;

&lt;h4 id=&quot;section-15&quot;&gt;참고문헌&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;D. Silver et al. “Mastering the game of Go with deep neural networks and tree search.” Nature 529.7587 (2016): 484-489.&lt;/li&gt;
  &lt;li&gt;문용직, 바둑의 발견, 1998&lt;/li&gt;
  &lt;li&gt;문용직, 수담과 무언 1, 2002&lt;/li&gt;
  &lt;li&gt;조환규, 이세돌과 인공지능 알파고의 ‘반상 결투’, 경향신문&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Tue, 08 Mar 2016 00:00:00 +0900</pubDate>
        <link>http://localhost:4000/2016/03/08/alphago</link>
        <guid isPermaLink="true">http://localhost:4000/2016/03/08/alphago</guid>
        
        
        <category>AlphaGo</category>
        
      </item>
    
      <item>
        <title>자연은 예술을 모방한다</title>
        <description>&lt;blockquote&gt;
  &lt;p&gt;한 시대의 예술은 그 시대의 세계관을 담는다. &lt;br /&gt;
예술은 세계에 대한 표상이며, 세계관의 투영이다. (조중걸)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;section&quot;&gt;‘빈 1900′ 모더니즘의 출현&lt;/h3&gt;
&lt;p&gt;19세기 말에서 20세기 초로 넘어가던 시기에 유럽에서 모더니즘이 출현했다. 당시 프랑스 파리와 함께 유럽의 문화적 수도였던 오스트리아 빈에서는 미술, 건축, 철학, 음악, 문학 등 거의 모든 분야에서 독창적이고 창조적인 흐름이 생겨났다. 대략 1890년부터 1918년까지 이어지는 시기를 ‘빈 1900’이라 일컫는다. 지그문트 프로이트, 아르놀트 쇤베르크, 에른스트 마흐, 오스카어 코코슈카, 아돌프 로스와 같은 사람들이 ‘빈 1900’에 활동했던 인물들이다.&lt;/p&gt;

&lt;p&gt;회화에서 빈 모더니즘은 구스타프 클림트, 오스카어 코코슈카, 에곤 실레로 대표된다. 이들은 기존의 주류 예술 양식과 결별을 선언하며 빈 분리파를 결성하였고, 파리의 모더니즘 경향과 발맞추어 표현주의 작품으로 새로운 시대를 열었다. 『통찰의 시대』의 저자 에릭 캔델은 이들 세 화가와 더불어 프로이트, 극작가 아르투어 슈니츨러를 ‘통찰의 시대’의 주인공으로 캐스팅했다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://t1.daumcdn.net/thumb/R1280x0/?fname=http://t1.daumcdn.net/brunch/service/user/aBL/image/AznPrkbzs9l9D9RGMOeqoG_JXCA&quot; alt=&quot;통찰의 시대&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;합리주의와 실재론을 벗어던지고&lt;/h3&gt;
&lt;p&gt;19세기 이전에는 합리주의자들의 독무대였다. 합리주의자들은 이성을 중시하고 감성은 무시했다. 합리주의와 경험주의를 통합하려 했던 18세기 철학자 이마누엘 칸트도 “도덕적 판단에 있어서 감성은 배제하고 이성을 활용해야 한다”고 했다.&lt;/p&gt;

&lt;p&gt;역사의 주도권은 “보편 개념이 실재한다”고 믿는 이상주의자들의 손에 쥐어져 있었다. 회화에서는 이상적이고 보편적인 아름다움을 추구한 작품만이 예술로 인정받았다. 솔직하고 직접적인 감각의 표현은 상스런 것이었다.&lt;/p&gt;

&lt;p&gt;합리주의와 실재론의 시대에는 자신감이 넘쳤다. 15세기 피렌체의 예술가들은 인간 지성에 대한 신뢰를 바탕으로 르네상스 시대를 꽃피웠다. 수학적 계산에 의한 선원근법을 회화에 활용하면서 삼차원의 세계를 이차원의 캔버스에 투영할 수 있었고 그것으로 세계를 온전히 모델링했다고 믿었다. 그리스와 로마의 고전적 예술이 그들의 규준이었다.&lt;/p&gt;

&lt;p&gt;빈의 모더니즘 화가들은 보편적 미를 추구하는 기존의 예술에 반기를 들고 과거의 모든 예술 양식으로부터 스스로를 ‘분리’했다. 예술 아카데미의 족쇄를 벗어던진 빈 분리파 화가들은 물었다. 예술에 있어서 불편한 감정은 숨겨야만 할 것인가. 예술은 이상적인 미를 추구해야 하는가. 보편적인 아름다움이 존재하는가.&lt;/p&gt;

&lt;p&gt;빈의 19세기 말은 그 이념과 양식에 있어 합리주의에서 경험주의로 실재론에서 유명론으로 관념론에서 실증주의로 이행하던 시기였다. 빈 대학교의 물리학자이자 과학철학자 에른스트 마흐가 과학철학의 영역에서 논리실증주의와 경험론의 기틀을 세웠고 빈 의과대학의 로키탄스키는 현대적 개념의 의학을 창시했다.&lt;/p&gt;

&lt;h3 id=&quot;section-2&quot;&gt;‘빈 1900′ 예술을 내면의 세계로 인도한 프로이트&lt;/h3&gt;
&lt;p&gt;빈 분리파 화가들에게 가장 많은 영향을 끼친 인물은 프로이트였다. 빈의 예술가들은 살롱을 통해 프로이트와 교류했다. 인간의 내면과 감정 표현에 몰두한 빈 표현주의 화가들은 프로이트의 무의식 이론과 마음의 작동 원리를 설명한 모델에 관심을 보였다.&lt;/p&gt;

&lt;p&gt;프로이트는 경험 과학의 영역에서 인간의 마음을 연구하여 무의식을 수면 위로 끌어올렸다. 그 전까지 무의식은 관심의 대상이 아니었다. 프로이트는 무의식적 동기가 우리 행위의 숨겨진 기반임을 임상을 통해 설명했다. 그는 압제된 무의식이 정신병의 근원이라고 했다. 프로이트가 마음의 과학에 관한 새로운 패러다임을 제시할 수 있었던 것은 에른스트 마흐와 로키탄스키가 다져 놓은 토양이 있었기에 가능한 것이었다.
당시 미술평론가들은 클림트의 작품이 “프로이트의 이론을 강렬하게 보여주는 시각적 표현”이라고 보았다. 프로이트가 “의식 아래에 묻힌 감정이 위장된 형태로 표면으로 부상한다”며 정신병의 근원으로 무의식을 지목했을 때, 클림트는 그것을 작품으로 표현하기 시작했다.&lt;/p&gt;

&lt;p&gt;클림트는 또한 다윈의 진화론을 읽었고 세포의 구조에 매료되었다. 클림트 작품에서 특징적으로 나타나는 장식 문양들은 생식세포를 상징하는 직사각형 정자와 타원형 난자를 도상학적으로 회화에 활용한 것이라고 말해진다.&lt;/p&gt;

&lt;p&gt;오스카어 코코슈카도 프로이트의 영향을 받았다. 그는 좀 더 자신만만했는데, 자신을 가리켜 “인간의 무의식적 마음을 밝혀내려는 데 프로이트와 쌍벽을 이룬 사람”이라고 자화자찬하기도 했다. 코코슈카는 초상화를 그릴 때 특히 손이 모델의 심리 상태를 표현한다고 보아서 ‘대화하는 손’을 묘사하는 데 몰두했다.
에곤 실레 역시 손과 자세가 감정을 드러내는데 효과적이라는 것을 알았다. 실레는 자신의 내면을 드러내는 데에도 거리낌이 없어, 과장된 몸짓과 일그러진 표정으로 성적 욕망과 감정을 여과 없이 드러내는 자화상을 많이 그렸다.&lt;/p&gt;

&lt;p&gt;클림트, 코코슈카, 실레는 많은 초상화를 남겼다. 이들이 모델의 내면과 무의식을 드러내는데 주력했기에, 에릭 캔델은 ‘빈 1900’을 예술사에서 ‘내면으로의 전환’이 이루어진 시기로 보았다. 빈 표현주의 화가들은 모델을 미화하려고 하지 않았기에 진정한 내면의 탐구가 가능했으며, 인간의 시지각이 감정을 어떻게 해석하는지에 대한 관심으로 이어질 수 있었다.&lt;/p&gt;

&lt;h3 id=&quot;section-3&quot;&gt;예술에서 ‘관람자의 몫’을 찾아 준 헬름홀츠&lt;/h3&gt;
&lt;p&gt;그런데 ‘빈 1900’시대의 경험론과 실증주의에 기반한 과학적 아이디어들이 화가들의 작품 활동에만 영향을 준 것이 아니었다. 미술사학자 알로이스 리글은 과학에서 얻은 통찰을 미술 비평에 접목했다. 이번에는 프로이트가 아니라 헬름홀츠였다.&lt;/p&gt;

&lt;p&gt;당대 독일의 생리학자이자 물리학자인 헤르만 폰 헬름홀츠는 시지각에 관련되는 신경 세포의 신호 전달 속도가 놀라우리만치 늦다는 것을 실험을 통해 알게 됐다. 헬름홀츠는 인간의 시각 시스템이 전적으로 정보에 의존하기보다는 기억에 기반한 무의식적 추론 과정을 통해 영상을 재구성한다고 결론지었다.
리글은 헬름홀츠의 통찰에서 영향 받아 미술 평론에 새로운 견해를 첨가하게 된다. 훗날 곰브리치가 ‘관람자의 몫’이라 부르게 되는 것으로, 예술이 독립적인 작품으로 존재하는 것이 아니라 관람자가 작품을 해석하는 행위까지 포함한다는 내용이다. 에릭 캔델이 예시했듯이, 관람자는 캔버스라는 이차원에 비슷해 보이게 그린 것을 시각 세계의 삼차원 묘사로 전환함으로써 화가와 협력할 뿐 아니라 캔버스에서 보는 것을 개인적인 관점에서 해석함으로써 그림에 의미를 덧붙인다.&lt;/p&gt;

&lt;p&gt;20세기 가장 영향력 있는 미술사학자로 평가되는 곰브리치 역시 헬름홀츠와 빈에서 나고 자란 칼 포퍼의 영향을 받았다. 곰브리치는 “기억이 미술의 지각에 핵심적인 역할을 한다”고 말했으며, ‘순수한 눈’ 같은 것은 없다고 확신했다. 현대의 인지심리학자 크리스 프리스는 “우리가 물질세계에 직접 접근하는 것처럼 느낄지 모르지만 그것은 우리 뇌가 빚어낸 환상”이라고 헬름홀츠의 통찰을 요약했다. 에릭 캔델의 말로 바꾸자면 “우리는 동시에 두 세계에 살고 있는 것이며, 현재 진행되고 있는 시각 경험은 두 세계의 대화인 셈”이다.&lt;/p&gt;

&lt;h3 id=&quot;section-4&quot;&gt;과학과 예술이 협력하는 시대&lt;/h3&gt;
&lt;p&gt;모더니즘이라는 새로운 차원을 제시한 ‘빈 1900’는 과학과 예술이 자유롭게 교류하며 대화했던 시기였으며, 오늘날 ‘빈 1900’의 정신을 이어받은 후예들이 ‘신경미학’이라는 분야를 탄생시켰다. 『통찰의 시대』는 과학과 예술이 어떻게 만날 수 있는지를 탐구한 신경과학자 에릭 캔델의 야심찬 프로젝트이며, 훌륭한 신경미학 개론서이다.&lt;/p&gt;

&lt;p&gt;신경과학의 발전에 힘입어 이제 우리는 감정을 담당하는 편도체(amygdala)와 이성적 사고를 담당하는 전전두엽이 어떻게 연결되고 어떤 영향을 주고받는지 알아가기 시작했다. 감성이 없으면 이성도 제대로 작동하지 않는다는 실험 결과 앞에서 합리주의는 더 이상 설 자리가 없다. 이성과 감성은 협력한다. 과학은 예술을 닮고 “자연은 예술을 모방한다.” (오스카 와일드)&lt;/p&gt;
</description>
        <pubDate>Thu, 15 Oct 2015 00:00:00 +0900</pubDate>
        <link>http://localhost:4000/2015/10/15/nature-mimics-art</link>
        <guid isPermaLink="true">http://localhost:4000/2015/10/15/nature-mimics-art</guid>
        
        
        <category>과학과 예술</category>
        
      </item>
    
  </channel>
</rss>
